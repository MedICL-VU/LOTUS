{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f30909fb1ea2d7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7989a428dcfb0dc9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader\n",
    "from monai.utils import first, set_determinism\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import L1Loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.inferers import LatentDiffusionInferer,DiffusionInferer\n",
    "from generative.losses import PatchAdversarialLoss, PerceptualLoss\n",
    "from generative.networks.nets import AutoencoderKL, DiffusionModelUNet, PatchDiscriminator\n",
    "from generative.networks.schedulers import DDPMScheduler, DDIMScheduler\n",
    "\n",
    "from mytransforms import *\n",
    "from utiles import *\n",
    "from generative.networks.nets import ControlNet\n",
    "from generative.inferers import ControlNetDiffusionInferer,ControlNetLatentDiffusionInferer\n",
    "print_config()\n",
    "\n",
    "set_determinism(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_dim = 64\n",
    "batch_size = 4\n",
    "img_space = 4\n",
    "train_name = 'your_model_name'\n",
    "start_time = time.time()\n",
    "\n",
    "input_data_dir = '/your_data_path'\n",
    "save_dir = '/results/Repaint3D/'+train_name\n",
    "save_vis_dir = os.path.join(save_dir,\"vis\")\n",
    "os.makedirs(save_vis_dir, exist_ok=True)\n",
    "\n",
    "img_list_pattern = list_nii_files(input_data_dir)\n",
    "img_list = natsorted(img_list_pattern)\n",
    "\n",
    "\n",
    "val_img_list = img_list\n",
    "\n",
    "val_files = [\n",
    "    {\n",
    "        \"image\":val_img_list[i],\n",
    "    }\n",
    "    for i in range(len(val_img_list))\n",
    "]\n",
    "\n",
    "\n",
    "channel = 0  # 0 = Flair\n",
    "assert channel in [0, 1, 2, 3], \"Choose a valid channel\"\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.Lambdad(keys=\"image\", func=lambda x: x[channel, :, :, :]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"], channel_dim=\"no_channel\"),\n",
    "        transforms.EnsureTyped(keys=[\"image\"]),\n",
    "        transforms.Orientationd(keys=[\"image\"], axcodes=\"LPI\"), # TODO Here change RAS to LPI\n",
    "        Copyd(keys=[\"image\"], new_key=[\"ori_img\"]),\n",
    "         transforms.Spacingd(keys=[\"image\"], pixdim=(img_space, img_space, img_space), mode=(\"bilinear\")),\n",
    "        # TODO here may add an affine later\n",
    "        transforms.ForegroundMaskD(keys = [\"image\"], new_key_prefix = \"mask\", threshold = 0.999, invert = True), # so we get a key called\n",
    "        \n",
    "        transforms.CenterSpatialCropd(keys=[\"maskimage\"], roi_size=(img_dim, img_dim, img_dim)),\n",
    "        transforms.CenterSpatialCropd(keys=[\"image\"], roi_size=(img_dim, img_dim, img_dim)),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "val_ds = CacheDataset(data = val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=8, persistent_workers=True)"
   ],
   "id": "2c71a1af3f6d43e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = DiffusionModelUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_channels=[256, 256, 512],\n",
    "    attention_levels=[False, False, True],\n",
    "    num_head_channels=[0, 0, 512],\n",
    "    num_res_blocks=2,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "model_path = 'pretrained_ddpm_model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "num_step = 1000\n",
    "scheduler = DDPMScheduler(num_train_timesteps=num_step , schedule=\"scaled_linear_beta\", beta_start=0.0005, beta_end=0.0195)\n",
    "# scheduler = DDIMScheduler(num_train_timesteps=num_step, schedule=\"scaled_linear_beta\", beta_start=0.0005, beta_end=0.0195)\n",
    "inferer = DiffusionInferer(scheduler)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-5)\n",
    "\n",
    "scaler = GradScaler()\n",
    "total_start = time.time()\n",
    "model.eval()\n"
   ],
   "id": "b08ab76bc99fb6c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    with autocast(enabled=True):\n",
    "        first_val_batch = first(val_loader)\n",
    "        images = first_val_batch[\"image\"].to(device)\n",
    "        masks = first_val_batch[\"maskimage\"].to(device)\n",
    "        masked_images = images*masks # TODO the condition for kidney outpainting\n",
    "        \n",
    "        \n",
    "        num_resample_steps = 2\n",
    "        timesteps = torch.Tensor((999,)).to(device).long()\n",
    "        progress_bar = tqdm(scheduler.timesteps)\n",
    "        val_image_inpainted = torch.randn_like(images).to(device)\n",
    "        \n",
    "        for t in progress_bar:\n",
    "            for u in range(num_resample_steps):\n",
    "                # get the known portion at t-1\n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(images).to(device)\n",
    "                    timesteps_prev = torch.Tensor((t - 1,)).to(noise.device).long()\n",
    "                    val_image_inpainted_prev_known = scheduler.add_noise(\n",
    "                        original_samples=masked_images, noise=noise, timesteps=timesteps_prev\n",
    "                    )\n",
    "                else:\n",
    "                    val_image_inpainted_prev_known = masked_images\n",
    "\n",
    "                # perform a denoising step to get the unknown portion at t-1\n",
    "                if t > 0:\n",
    "                    timesteps = torch.Tensor((t,)).to(noise.device).long()\n",
    "                    model_output = model(val_image_inpainted, timesteps=timesteps)\n",
    "                    val_image_inpainted_prev_unknown, _ = scheduler.step(model_output, t, val_image_inpainted)\n",
    "\n",
    "                # combine known and unknown using the mask\n",
    "                val_image_inpainted = torch.where(\n",
    "                    masks == 1, val_image_inpainted_prev_known, val_image_inpainted_prev_unknown\n",
    "                )\n",
    "\n",
    "                # perform resampling\n",
    "                if t > 0 and u < (num_resample_steps - 1):\n",
    "                    # sample x_t from x_t-1\n",
    "                    noise = torch.randn_like(images).to(device)\n",
    "                    val_image_inpainted = (\n",
    "                        torch.sqrt(1 - scheduler.betas[t - 1]) * val_image_inpainted\n",
    "                        + torch.sqrt(scheduler.betas[t - 1]) * noise\n",
    "                    )\n"
   ],
   "id": "7ef686b87387b364",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vis_results(*tensors, idx):  # TODO: to visualize the midian result\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "    t_n = ['I', 'mask','mI', 'op_image']\n",
    "    len_tensor = len(tensors)\n",
    "    for k in range(3):\n",
    "        for i, tensor in enumerate(tensors, start=1):\n",
    "            ax = fig.add_subplot(3, len_tensor, k*len_tensor + i) # show all 3 panels\n",
    "            # Assuming your tensor has the shape (1,1,128,128,128) and it's on CUDA\n",
    "            tensor = tensor.cpu()  # Move the tensor back to CPU for visualization\n",
    "            # print(f\"tensor's shape is {tensor.shape}\")\n",
    "            if k == 0:\n",
    "                tensor_slice = tensor[idx, 0, :, tensor.shape[-1]//2, :].detach().numpy()  # Select the desired slice and convert to numpy\n",
    "            if k == 1:\n",
    "                tensor_slice = tensor[idx, 0, tensor.shape[-1]//2, :, :].detach().numpy()  # Select the desired slice and convert to numpy\n",
    "            if k == 2:\n",
    "                tensor_slice = tensor[idx, 0, :, :, tensor.shape[-1]//2].detach().numpy()  # Select the desired slice and convert to numpy\n",
    "\n",
    "            ax.imshow(tensor_slice, cmap='gray', vmin=0, vmax=1)\n",
    "            ax.set_title(t_n[i - 1])  # Give each tensor image a title\n",
    "            ax.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "for i in range(images.shape[0]):\n",
    "    vis_results(images, masks, masked_images, val_image_inpainted, idx = i)"
   ],
   "id": "a7479da80a411b95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "74799b90cb472907"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T00:49:33.037212Z",
     "start_time": "2024-11-25T00:49:33.033133Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "52d31016573ec247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf0da79f693edb88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
